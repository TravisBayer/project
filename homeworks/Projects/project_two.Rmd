---
title: "Project Two"
output:
  pdf_document: default
  html_document: default
---

Due Oct. 21 at 11:59 PM. 

For this first part of the exam, you can either use `surveys_complete.csv` or your own data. If you are using your own data, you must have data in which you think you have a numerical predictor variable and a numerical response variable. If you are using `surveys_complete`, you can use weight and hindfoot_length for this.

Save this file in your `projects` directory. You can either save it in a project two subdirectory, or just put it in projects. Either way is fine.


1) Load in your data. Which variable will you be using as a predictor, and which as a response? (5 pts)

```{r}
>library(tidyverse)
> bats <- read.csv("/cloud/project/homeworks/batdata.csv")
> bats

Forearm length will be my predictor and the response will be the mass of the bat.
```

```
# Answer which column is predictor and which is response
```

2) Plot the two against each other with a scatter plot. Do the data appear to be related linearly? (5 pts)


```{r}
> ggplot(bats, aes(x = forearmlength_mm, y = mass_bat_g, color = sex)) + geom_point() + geom_smooth(method = "lm", color = "navy", size = 0.5, fill = "deeppink") + labs(y = "Mass of bats (g)", x = "Forearm length (mm)", title = "Mass of bat vs forearm length")

The 2 are not related linearly.
```



3) Fit the linear model. View the summary. (5 pts)


```{r}

> model_fitted <- lm(mass_bat_g ~ forearmlength_mm, data = bats)
> summary(model_fitted)

```

4) Does the summary make sense when you compare it to the plot you made? Does our model have good predictive power? Evaluate the residual standard error, intercept, and R-Squared in particular. Would you say your predictor predicts the response?  (10 pts)


```
The summary makes a lot of sense. The model has essentially no predictive power. The standard error is way too large, the intercept is a massive negative value, and the r squared is so small showing us the 2 are not related to one another at all. My predictor DOES NOT predict the response.
```


5) Plot the model on the graph. Increase the size of the text so it is comfortably readable at 5 feet. Make sure axis labels are readable and not overlapping with one another. (5 pts)

```
> ggplot(bats, aes(x = forearmlength_mm, y = mass_bat_g, color = sex)) + geom_point(size = 1) + geom_smooth(method = "lm", color = "navy", size = 0.5, fill = "deeppink") + labs(y = "Mass of bats (g)", x = "Forearm length (mm)", title = "Mass of bat vs forearm length") + theme(text = element_text(size = 16), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 15))
```


6) Check the normality of the residuals. Do they look OK? Are we violating assumptions? (5 pts)

```{r}
> augment(model_fit) -> augmented_fitted
> qqnorm(augmented_fitted$.resid)
> qqline(augmented_fitted$.resid, col = "deeppink")

```

Why is normality of residuals important? 

```{r}

Becuase it will tell you how normally distributed your residuals are. If your residuals are not normal then there may be problem with the model fit, stability, and reliability.
```

7) If you are using `surveys_complete`: Is there interspecific variation in the linear model? Hint: look at our prior work with facet plots. (15 pts) 

If you are *not* using  `surveys_complete`: Do you think there are groupings within your data that may have a separate linear model? Try grouping the data by that variable and redoing the lm. If this would not make sense for your data, you may also attempt to do multiple predictor variables. (15 pts)

```{r}
> plot <- ggplot(bats, aes(x = ectoparasites, y = mass_bat_g)) + geom_point(size = 1) + geom_smooth(method = "lm", color = "navy", size = 0.5, fill = "deeppink") + labs(y = "Mass of bats (g)", x = "Ectoparasite presence and type", title = "Ectoparasites vs mass of bat") + theme(text = element_text(size = 16), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 15))

*code not working properly, you had me put this in here to remind you about it*****
```

## Part Two

In this portion, you are free to use your own data if you have a categorical predictor variable and a response variable. Otherwise, you may use the columns sex and weight in `surveys_complete`

1) First, plot the data grouped by sex (5 pts)

```{r}
> surveys_complete <- read_csv("/cloud/project/data/surveys.csv")
>surveys_comp <- na.omit(surveys_complete)
> ggplot(data = surveys_comp, aes(x = sex, y = weight, color = sex)) + geom_jitter() + labs(x = "Sex", y = "Weight") + stat_summary(fun.data = "mean_se")

```

2) Try an ANOVA of this data (5 pt)

```{r}
ggplot(surveys_comp, aes(x = sex, y = weight, color = sex)) + geom_jitter() + labs(x = "Sex", y = "Weight") + stat_summary(fun.data = "mean_se")

> aov(model_fit) -> anova_model_fit
> summary(anova_model_fit)
               Df   Sum Sq Mean Sq F value Pr(>F)
sex             1     2869    2869   2.255  0.133
Residuals   30674 39033425    1272   
```

3) How about a linear model? What information does this give you that an ANOVA can't? (5 pts)


```{r}
model_fit <- lm(weight ~ sex, data = surveys_comp)
summary(model_fit)

Call:
lm(formula = weight ~ sex, data = surveys_comp)

Residuals:
   Min     1Q Median     3Q    Max 
-38.08 -22.08  -5.47   5.53 237.92 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  41.4701     0.2954 140.391   <2e-16 ***
sexM          0.6124     0.4078   1.502    0.133    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 35.67 on 30674 degrees of freedom
Multiple R-squared:  7.351e-05,	Adjusted R-squared:  4.091e-05 
F-statistic: 2.255 on 1 and 30674 DF,  p-value: 0.1332
```

```
The Anova will give you something like residuals, whereas the linear model gives all that and others such as r-squared, intercepts, and est. stndrd error.
```

3) Plot the lm with the data, with points colored by sex. (10 pts)


```{r}
> ggplot(data = surveys_comp, aes(x = sex, y = weight, color = sex)) + geom_point() + geom_smooth(method = "lm") + annotate("text", x = "NA", y = 250, label = "R^2 == 0.988", parse = T, size = 5)
```

4) Choose any model we've looked at so far, but use two predictor variables. Perform an LM, plot the results, and state if this changes your interpretation of the relationship between variables (10 pts)

```{r}

> model_fit <- lm(hindfoot_length ~ sex + weight, data = surveys_comp)
> summary(model_fit)
```

```{r}
> ggplot(surveys_comp, aes(x = weight, y = hindfoot_length, color = sex)) + geom_point() + geom_smooth(method = "lm") + annotate("text", x = 40, y = 30, label = "R^2 == 0.988", parse = T, size = 5)
```

```
I think it gives me a better visualization and shows the spread a little better. It changes my interpretation a little because I can see the male lm line has a slightly steeper slope than does the female lm line.
```

## Part Three


1) Add and commit this document (5 pts)

```
Document was committed
```

2) Push your changes to github (10 pts)

```
Document was pushed to Github
```



# MS students

My expectation is that you'll do this with your own data. If any part of this doesn't make sense with your data, please get in touch ASAP so we can work it out.
